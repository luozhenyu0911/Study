{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef1cb363",
   "metadata": {},
   "source": [
    "# 这是2024/03/03 对CSDN中python中pandas的复习"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa276dd",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Data School‘s top 25 pandas tricks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d551cea8",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "    df = df.rename({'col one':'col_one', 'col two':'col_two'}, axis='columns')\n",
    "    df.columns = df.columns.str.replace(' ', '_')  将前者替换成后者\n",
    "    \n",
    "    对数据框的列名添加前后缀\n",
    "    df.add_prefix('X_')\n",
    "    df.add_suffix('_Y')\n",
    "    \n",
    "    Let's say you need to select only the numeric columns. You can use the select_dtypes() method:\n",
    "    drinks.select_dtypes(include='number').head()\n",
    "    drinks.select_dtypes(include='object').head()\n",
    "    drinks.select_dtypes(include=['number', 'object', 'category', 'datetime']).head()\n",
    "    drinks.select_dtypes(exclude='number').head()\n",
    "    \n",
    "    data中数据类型转换\n",
    "    df.astype({'col_one':'float', 'col_two':'float'}).dtypes\n",
    "    \n",
    "    from glob import glob\n",
    "    stock_files = sorted(glob('data/stocks*.csv'))\n",
    "    stock_files  返回一个列表\n",
    "    ['data/stocks1.csv', 'data/stocks2.csv', 'data/stocks3.csv']\n",
    "    重点\n",
    "    pd.concat((pd.read_csv(file) for file in stock_files))\n",
    "    Unfortunately, there are now duplicate values in the index. \n",
    "    pd.concat((pd.read_csv(file) for file in stock_files), ignore_index=True)\n",
    "    \n",
    "    Split a DataFrame into two random subsets\n",
    "    随机抽取data的subdata\n",
    "    movies_1 = movies.sample(frac=0.75, random_state=1234)\n",
    "    movies_2 = movies.drop(movies_1.index)\n",
    "    movies_1 和movies_2的 “和” 即为 movies\n",
    "    \n",
    "    movies[movies.genre.isin(['Action', 'Drama', 'Western'])].head() *\n",
    "    movies[(movies.genre == 'Action') |\n",
    "           (movies.genre == 'Drama') |\n",
    "           (movies.genre == 'Western')].head()\n",
    "    上面两种方法效果是一样的\n",
    "    取上面 * 的对立面\n",
    "    movies[~movies.genre.isin(['Action', 'Drama', 'Western'])].head()\n",
    "    \n",
    "    Split a string into multiple columns  将一列拆分多列\n",
    "    df[['first', 'middle', 'last']] = df.name.str.split(' ', expand=True)\n",
    "    df['city'] = df.location.str.split(', ', expand=True)[0]\n",
    "    \n",
    "    Expand a Series of lists into a DataFrame  将一个list的列分为单个的列\n",
    "    df = pd.DataFrame({'col_one':['a', 'b', 'c'], 'col_two':[[10, 40], [20, 50], [30, 60]]})\n",
    "    df_new = df.col_two.apply(pd.Series)\n",
    "    pd.concat([df, df_new], axis='columns')\n",
    "\n",
    "    Combine the output of an aggregation with a DataFrame  增加一列的方式\n",
    "    total_price = orders.groupby('order_id').item_price.transform('sum')\n",
    "    orders['total_price'] = total_price\n",
    "    orders['percent_of_total'] = orders.item_price / orders.total_price\n",
    "\n",
    "    titanic.describe().loc['min':'max', 'Pclass':'Parch']\n",
    "\n",
    "    titanic.groupby(['Sex', 'Pclass']).Survived.mean()\n",
    "    titanic.groupby(['Sex', 'Pclass']).Survived.mean().unstack()\n",
    "\n",
    "    22. Create a pivot table\n",
    "    titanic.pivot_table(index='Sex', columns='Pclass', values='Survived', aggfunc='mean')\n",
    "    titanic.pivot_table(index='Sex', columns='Pclass', values='Survived', aggfunc='count',margins=True)\n",
    "\n",
    "    23. Convert continuous data into categorical data 将连续值转为分段变量\n",
    "    pd.cut(titanic.Age, bins=[0, 18, 25, 99], labels=['child', 'young adult', 'adult']).head(10)\n",
    "\n",
    "    24. Change display options\n",
    "    pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "    25. Style a DataFrame\n",
    "    format_dict = {'Date':'{:%m/%d/%y}', 'Close':'${:.2f}', 'Volume':'{:,}'}\n",
    "    stocks.style.format(format_dict)\n",
    "    (stocks.style.format(format_dict)\n",
    "     .hide_index()\n",
    "     .highlight_min('Close', color='red')\n",
    "     .highlight_max('Close', color='lightgreen')\n",
    "    )\n",
    "    (stocks.style.format(format_dict)\n",
    "     .hide_index()\n",
    "     .background_gradient(subset='Volume', cmap='Blues')\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5636c7b0",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## pandas 个人不熟"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96de5af3",
   "metadata": {
    "hidden": true
   },
   "source": [
    "\n",
    "    # use the '|' operator to specify that a row can match any of the three criteria\n",
    "    movies[(movies.genre == 'Crime') | (movies.genre == 'Drama') | (movies.genre == 'Action')].head(10)\n",
    "\n",
    "    # or equivalently, use the 'isin' method\n",
    "    movies[movies.genre.isin(['Crime', 'Drama', 'Action'])].head(10)\n",
    "\n",
    "    # specify how many rows to read\n",
    "    ufo = pd.read_csv('data/ufo.csv',nrows=4)  # 取了前三行\n",
    "    \n",
    "    # 删除数据框中不是数值型的object\n",
    "\n",
    "    drinks = pd.read_csv('data/drinks.csv')\n",
    "    # only include numeric columns in the DataFrame\n",
    "    import numpy as np\n",
    "    drinks.select_dtypes(include=[np.number]).dtypes\n",
    "\n",
    "    # 选择数据框中要describe的列\n",
    "    # pass the string 'all' to describe all columns\n",
    "    drinks.describe(include='all')\n",
    "    # # pass a list of data types to only describe certain types\n",
    "    drinks.describe(include=['object', 'float64'])\n",
    "    # pass a list even if you only want to describe a single data type\n",
    "    drinks.describe(include=['object'])\n",
    "\n",
    "    # use the boolean Series to filter the DataFrame\n",
    "    orders[orders.item_name.str.contains('Chicken')].head()\n",
    "    ## orders.item_name.str.contains('Chicken')返回一系列bool值\n",
    "\n",
    "    # string methods can be chained together\n",
    "    orders.choice_description.str.replace('[', '').str.replace(']', '').head()\n",
    "\n",
    "    #支持正则表达式\n",
    "    # many pandas string methods support regular expressions (regex)\n",
    "    orders.choice_description.str.replace('[\\[\\]]', '').head()\n",
    "\n",
    "    # convert a boolean Series to an integer (False = 0, True = 1)\n",
    "    orders.item_name.str.contains('Chicken').astype(int).value_counts()  \n",
    "    # 注意 .value_counts 与 .value_counts()的区别\n",
    "\n",
    "    # other aggregation functions (such as 'max') can also be used with groupby\n",
    "    drinks.groupby('continent').beer_servings.max()\n",
    "    # multiple aggregation functions can be applied simultaneously\n",
    "    drinks.groupby('continent').beer_servings.agg(['count', 'mean', 'min', 'max'])\n",
    "\n",
    "    NA 值\n",
    "    # if 'any' values are missing in a row, then drop that row\n",
    "    ufo.dropna(how='any').shape  # 只要含有Nan的值就drop\n",
    "    # if 'all' values are missing in a row, then drop that row (none are dropped in this case)\n",
    "    ufo.dropna(how='all').shape\n",
    "    # if 'any' values are missing in a row (considering only 'City' and 'Shape Reported'), then drop that row\n",
    "    ufo.dropna(subset=['City', 'Shape Reported'], how='any').shape\n",
    "    # if 'all' values are missing in a row (considering only 'City' and 'Shape Reported'), then drop that row\n",
    "    ufo.dropna(subset=['City', 'Shape Reported'], how='all').shape\n",
    "    # 'value_counts' does not include missing values by default\n",
    "    ufo['Shape Reported'].value_counts().head()\n",
    "    # explicitly include missing values\n",
    "    ufo['Shape Reported'].value_counts(dropna=False).head()  #  将 NaN算一个object进行统计\n",
    "    # fill in missing values with a specified value\n",
    "    ufo['Shape Reported'].fillna(value='VARIOUS', inplace=True)\n",
    "    # confirm that the missing values were filled in\n",
    "    ufo['Shape Reported'].value_counts().head()\n",
    "\n",
    "    drinks.loc[23, 'beer_servings']\n",
    "    drinks.set_index('country', inplace=True)\n",
    "    drinks.index.name = None   # 设置index的名字\n",
    "    drinks.reset_index(inplace=True)  # 还原index \n",
    "    # you can interact with any DataFrame using its index and columns\n",
    "    drinks.describe().loc['25%', 'beer_servings']\n",
    "\n",
    "    drinks.continent.value_counts()['Africa']\n",
    "    # any Series can be sorted by its values\n",
    "    drinks.continent.value_counts().sort_values()\n",
    "    # any Series can also be sorted by its index\n",
    "    drinks.continent.value_counts().sort_index()\n",
    "\n",
    "    # concatenate the 'drinks' DataFrame with the 'population' Series (aligns by the index)\n",
    "    pd.concat([drinks, people], axis=1)\n",
    "\n",
    "    # calculate the total annual beer servings for each country\n",
    "    (drinks.beer_servings * people).head()\n",
    "    #两个数据框对应的值相乘\n",
    "\n",
    "    # create the 'Sex_male' dummy variable using the 'map' method\n",
    "    train['Sex_male'] = train.Sex.map({'female':0, 'male':1})\n",
    "    train.head()\n",
    "\n",
    "    # create a new 'Location' Series (must use bracket notation to define the Series name)\n",
    "    ufo['Location'] = ufo.City + ', ' + ufo.State\n",
    "\n",
    "    ufo.rename(columns={'Colors Reported':'Colors_Reported', 'Shape Reported':'Shape_Reported'}, inplace=True)\n",
    "    ufo.columns\n",
    "\n",
    "    # remove multiple columns at once\n",
    "    ufo.drop(['City', 'State'], axis=1, inplace=True)\n",
    "    # remove multiple rows at once (axis=0 refers to rows)\n",
    "    ufo.drop([0, 1], axis=0, inplace=True)\n",
    "\n",
    "    # create a list in which each element refers to a DataFrame row: True if the row satisfies the condition, False otherwise\n",
    "    booleans = []\n",
    "    for length in movies.duration:\n",
    "        if length >= 200:\n",
    "            booleans.append(True)\n",
    "        else:\n",
    "            booleans.append(False)\n",
    "    is_long = pd.Series(booleans)\n",
    "    is_long.head()\n",
    "    # use bracket notation with the boolean Series to tell the DataFrame which rows to display\n",
    "    movies[is_long]\n",
    "\n",
    "    # simplify the steps above: no need to write a for loop to create 'is_long' since pandas will broadcast the comparison\n",
    "    is_long = movies.duration >= 200\n",
    "    movies[is_long]\n",
    "\n",
    "    # or equivalently, write it in one line (no need to create the 'is_long' object)\n",
    "    movies[movies.duration >= 200]\n",
    "\n",
    "    处理NA值\n",
    "    # if 'any' values are missing in a row (considering only 'City' and 'Shape Reported'), then drop that row\n",
    "    ufo.dropna(subset=['City', 'Shape Reported'], how='any').shape\n",
    "\n",
    "    # fill in missing values with a specified value\n",
    "    ufo['Shape Reported'].fillna(value='VARIOUS', inplace=True)\n",
    "\n",
    "    about index\n",
    "    # restore the index name, and move the index back to a column\n",
    "    drinks.index.name = 'country'\n",
    "    drinks.reset_index(inplace=True)\n",
    "\n",
    "    # comparison operators work with ordered categories\n",
    "    df.loc[df.quality > 'good', :]\n",
    "\n",
    "    get_dummies的用法\n",
    "    # pass the DataFrame to 'get_dummies' and specify which columns to dummy (it drops the original columns)\n",
    "    pd.get_dummies(train, columns=['Sex', 'Embarked']).head()\n",
    "\n",
    "\n",
    "    # only consider a subset of columns when identifying duplicates\n",
    "    users.duplicated(subset=['age', 'zip_code']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192270c",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## pandas一些不熟悉的知识点（二）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34548d1c",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "581503a0",
   "metadata": {
    "hidden": true
   },
   "source": [
    "    ratings.loc[ratings.movie_id == 1, :].head()\n",
    "    如果有相同id的列可以直接merge\n",
    "    movie_ratings = pd.merge(movies, ratings)\n",
    "    pd.merge(movies, ratings, left_on='m_id', right_on='movie_id').head()\n",
    "\n",
    "    movies = movies.set_index('m_id')\n",
    "\n",
    "    A = pd.DataFrame({'color': ['green', 'yellow', 'red'], 'num':[1, 2, 3]})\n",
    "\n",
    "    2.关于category\n",
    "    # data types are automatically detected\n",
    "    drinks.dtypes\n",
    "\n",
    "    # example of a single aggregation function after a groupby\n",
    "    drinks.groupby('continent').beer_servings.mean()\n",
    "\n",
    "    # multiple aggregation functions can be applied simultaneously\n",
    "    drinks.groupby('continent').beer_servings.agg(['mean', 'min', 'max'])\n",
    "\n",
    "    About MultiIndex in pandas\n",
    "    stocks.groupby('Symbol').Close.mean()\n",
    "    ser = stocks.groupby(['Symbol', 'Date']).Close.mean()\n",
    "    ser.index #  MultiIndex\n",
    "    ser.unstack()\n",
    "\n",
    "    df = stocks.pivot_table(values='Close', index='Symbol', columns='Date')\n",
    "    df\n",
    "    此时的df 与ser 是一样的\n",
    "\n",
    "    Selection from Series with MultiIndex\n",
    "    ser.loc['AAPL']\n",
    "    ser.loc['AAPL', '2016-10-03']\n",
    "    ser.loc[:, '2016-10-03']\n",
    "\n",
    "    DataFrame with MultiIndex\n",
    "    stocks.set_index(['Symbol', 'Date'], inplace=True)\n",
    "    stocks.sort_index(inplace=True)\n",
    "\n",
    "    Selection from DataFrame with MultiIndex\n",
    "    stocks.loc[('AAPL', '2016-10-03'), :]\n",
    "    stocks.loc[('AAPL', '2016-10-03'), 'Close']\n",
    "    stocks.loc[['AAPL', 'MSFT'], :]\n",
    "    stocks.loc[(['AAPL', 'MSFT'], '2016-10-03'), :]\n",
    "    stocks.loc[('AAPL', ['2016-10-03', '2016-10-04']), 'Close']\n",
    "\n",
    "    # old way to drop rows: specify labels and axis\n",
    "    ufo.drop([0, 1], axis=0).head()\n",
    "    ufo.drop([0, 1], axis='index').head()\n",
    "    # old way to drop columns: specify labels and axis\n",
    "    ufo.drop(['City', 'State'], axis=1).head()\n",
    "    ufo.drop(['City', 'State'], axis='columns').head()\n",
    "\n",
    "    4. rename and reindex now accept \"axis\" keyword\n",
    "    New in 0.21.0\n",
    "    # old way to rename columns: specify columns\n",
    "    ufo.rename(columns={'City':'CITY', 'State':'STATE'}).head()\n",
    "\n",
    "    # new way to rename columns: specify mapper and axis\n",
    "    ufo.rename({'City':'CITY', 'State':'STATE'}, axis='columns').head()\n",
    "    # note: mapper can be a function\n",
    "    ufo.rename(str.upper, axis='columns').head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105505bc",
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b77722cd",
   "metadata": {},
   "source": [
    "## 关于pandas 自己写的难记住的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd133c99",
   "metadata": {},
   "source": [
    "### \n",
    "    def dis_type(data):\n",
    "    if data['distance'] <=2000:\n",
    "        return '0-2000'\n",
    "    elif data['distance'] >=2001 and data['distance'] <=4000:\n",
    "        return '2001-4000'\n",
    "    else:\n",
    "        return '>4000'\n",
    "    #     return data\n",
    "    hyper.loc[:, \"dis_type\"] = hyper.apply(dis_type, axis=1)\n",
    "\n",
    "    pands 取指定的列名及取包含某些字符串的行\n",
    "\n",
    "    df2=df1.loc[:,MB_E15_MB_sampleid] #MB_E15_MB_sampleid是的list\n",
    "    MB_E15_MB_sample=df2[df2.gene.str.contains('ENSMUSG00000020893')].T\n",
    "    #  ENSMUSG00000020893是个基因，可能有很多的转录本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340ed001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2a6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f0fbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b111b1ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9584175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
